{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "539c9d47",
   "metadata": {},
   "source": [
    "# Cryptocurrency Trading Algorithm\n",
    "\n",
    "This notebook implements a complete cryptocurrency trading strategy using machine learning. The implementation includes:\n",
    "\n",
    "1. Data Collection and Preprocessing\n",
    "2. Technical Analysis\n",
    "3. Feature Engineering\n",
    "4. Model Training and Optimization\n",
    "5. Backtesting\n",
    "6. Performance Visualization\n",
    "\n",
    "The strategy uses XGBoost for prediction and incorporates various technical indicators for feature generation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6537dedb",
   "metadata": {},
   "source": [
    "## 1. Data Collection and Preprocessing\n",
    "\n",
    "In this section, we:\n",
    "1. Load historical cryptocurrency price data\n",
    "2. Handle missing values\n",
    "3. Ensure data integrity and chronological order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adcb4dc",
   "metadata": {},
   "source": [
    "## 2. Technical Analysis\n",
    "\n",
    "Calculate essential technical indicators:\n",
    "- RSI (Relative Strength Index)\n",
    "- Bollinger Bands\n",
    "- Moving Averages\n",
    "- ATR (Average True Range)\n",
    "- Volume Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b79665",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering\n",
    "\n",
    "In this section, we:\n",
    "1. Generate trading signals from technical indicators\n",
    "2. Handle feature scaling and normalization\n",
    "3. Create derived features\n",
    "4. Analyze feature correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc913b4",
   "metadata": {},
   "source": [
    "## 4. Model Training and Optimization\n",
    "\n",
    "This section covers:\n",
    "1. Data splitting (train/test)\n",
    "2. Class imbalance handling with SMOTE\n",
    "3. XGBoost model training\n",
    "4. Hyperparameter optimization\n",
    "5. Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4b9ab5",
   "metadata": {},
   "source": [
    "## 5. Backtesting\n",
    "\n",
    "Implement and evaluate the trading strategy:\n",
    "1. Execute trades based on model predictions\n",
    "2. Calculate performance metrics\n",
    "3. Track portfolio value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d917d63e",
   "metadata": {},
   "source": [
    "## 6. Trading Performance Visualization\n",
    "\n",
    "Create interactive visualizations of:\n",
    "1. Price action with buy/sell signals\n",
    "2. Volume analysis\n",
    "3. Portfolio performance\n",
    "4. Trading metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b28ec03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Core Python & Environment ---\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "# --- Data Handling & Numerics ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Technical Analysis ---\n",
    "from ta.momentum import RSIIndicator # Relative Strength Index\n",
    "from ta.volatility import AverageTrueRange, BollingerBands\n",
    "from ta.trend import SMAIndicator\n",
    "\n",
    "# --- Machine Learning ---\n",
    "import xgboost as xgb # ML Model\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "from imblearn.over_sampling import SMOTE # Synthetic Minority Over-sampling Technique\n",
    "\n",
    "# --- Plotting ---\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# --- Configure Logging ---\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - [%(funcName)s] - %(message)s')\n",
    "\n",
    "# --- Suppress Specific Warnings ---\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='pandas')\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='sklearn')\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='xgboost')\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "print(\"✅ Setup Complete: Libraries imported and configuration set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c46200f",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing\n",
    "\n",
    "In this section, we'll:\n",
    "1. Load our historical price data\n",
    "2. Apply initial data cleaning\n",
    "3. Handle missing values and outliers\n",
    "4. Calculate basic technical indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4e27e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(file_path='test_df_features.csv'):\n",
    "    try:\n",
    "        # Load the data\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Convert timestamp to datetime if needed\n",
    "        if 'timestamp' in df.columns:\n",
    "            df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "            df.set_index('timestamp', inplace=True)\n",
    "        \n",
    "        # Sort by index to ensure chronological order\n",
    "        df = df.sort_index()\n",
    "        \n",
    "        # Handle missing values\n",
    "        missing_count = df.isnull().sum()\n",
    "        if missing_count.any():\n",
    "            logging.warning(f'Found missing values:\\n{missing_count[missing_count > 0]}')\n",
    "            # Forward fill for technical indicators\n",
    "            df = df.fillna(method='ffill')\n",
    "            # Any remaining NaNs are filled with column median\n",
    "            df = df.fillna(df.median())\n",
    "        \n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logging.error(f'Error loading data: {str(e)}')\n",
    "        raise\n",
    "\n",
    "# Load the data\n",
    "try:\n",
    "    df = load_and_preprocess_data()\n",
    "    print(f'✅ Data loaded successfully. Shape: {df.shape}')\n",
    "    print('\\nFirst few rows of the data:')\n",
    "    display(df.head())\n",
    "    \n",
    "    print('\\nDataset Info:')\n",
    "    display(df.info())\n",
    "except Exception as e:\n",
    "    print(f'❌ Failed to load data: {str(e)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc759b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_technical_indicators(df):\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise TypeError('Input must be a pandas DataFrame')\n",
    "    \n",
    "    if 'close' not in df.columns:\n",
    "        raise ValueError(\"DataFrame must contain 'close' price column\")\n",
    "    \n",
    "    try:\n",
    "        # RSI\n",
    "        rsi = RSIIndicator(close=df['close'], window=14)\n",
    "        df['rsi'] = rsi.rsi()\n",
    "        \n",
    "        # Bollinger Bands\n",
    "        bb = BollingerBands(close=df['close'], window=20, window_dev=2)\n",
    "        df['bb_upper'] = bb.bollinger_hband()\n",
    "        df['bb_lower'] = bb.bollinger_lband()\n",
    "        df['bb_mid'] = bb.bollinger_mavg()\n",
    "        df['bb_pct_b'] = (df['close'] - df['bb_lower']) / (df['bb_upper'] - df['bb_lower'])\n",
    "        \n",
    "        # Moving Averages\n",
    "        df['sma_20'] = SMAIndicator(close=df['close'], window=20).sma_indicator()\n",
    "        df['sma_50'] = SMAIndicator(close=df['close'], window=50).sma_indicator()\n",
    "        df['ma_cross'] = (df['sma_20'] > df['sma_50']).astype(int)\n",
    "        \n",
    "        # Price momentum\n",
    "        df['price_momentum'] = df['close'].pct_change(5)\n",
    "        \n",
    "        # Average True Range\n",
    "        if all(col in df.columns for col in ['high', 'low']):\n",
    "            atr = AverageTrueRange(high=df['high'], low=df['low'], close=df['close'], window=14)\n",
    "            df['atr'] = atr.average_true_range()\n",
    "            df['atr_pct'] = df['atr'] / df['close']  # ATR as percentage of price\n",
    "            \n",
    "        # Volume metrics\n",
    "        if 'volume' in df.columns:\n",
    "            df['volume_pct_change'] = df['volume'].pct_change()\n",
    "        \n",
    "        # Remove old duplicate columns\n",
    "        columns_to_drop = ['BB_hband', 'BB_lband', 'BB_mavg', 'RSI', 'SMA_long', 'SMA_short']\n",
    "        df = df.drop(columns=[col for col in columns_to_drop if col in df.columns])\n",
    "        \n",
    "        # Remove any remaining NaN values from indicator calculations\n",
    "        df.dropna(inplace=True)\n",
    "        \n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logging.error(f'Error calculating technical indicators: {str(e)}')\n",
    "        raise\n",
    "\n",
    "# Calculate technical indicators\n",
    "try:\n",
    "    df = calculate_technical_indicators(df)\n",
    "    print('✅ Technical indicators calculated successfully')\n",
    "    print(f'Final dataset shape: {df.shape}')\n",
    "    \n",
    "    # Display summary statistics\n",
    "    print('\\nSummary statistics of technical indicators:')\n",
    "    display(df[['rsi', 'bb_upper', 'bb_lower', 'bb_mid', 'atr']].describe())\n",
    "except Exception as e:\n",
    "    print(f'❌ Failed to calculate technical indicators: {str(e)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b9f8fb",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "In this section, we'll create trading signals and labels based on our technical indicators. We'll focus on:\n",
    "1. RSI-based signals with dynamic thresholds\n",
    "2. Bollinger Bands signals\n",
    "3. Feature normalization and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c92c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rsi_quantile_thresholds(rsi_series, lower_quantile=0.2, upper_quantile=0.8):\n",
    "    \"\"\"Calculate RSI thresholds based on historical distribution.\n",
    "    \n",
    "    Args:\n",
    "        rsi_series (pd.Series): Series containing RSI values\n",
    "        lower_quantile (float): Quantile for oversold threshold (default: 0.2)\n",
    "        upper_quantile (float): Quantile for overbought threshold (default: 0.8)\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (lower_threshold, upper_threshold)\n",
    "    \"\"\"\n",
    "    if not isinstance(rsi_series, pd.Series):\n",
    "        raise TypeError('rsi_series must be a pandas Series')\n",
    "    \n",
    "    if rsi_series.empty:\n",
    "        raise ValueError('RSI series is empty')\n",
    "    \n",
    "    # Validate quantile values\n",
    "    if not (0 < lower_quantile < upper_quantile < 1):\n",
    "        raise ValueError('Quantiles must be between 0 and 1, and lower must be less than upper')\n",
    "    \n",
    "    # Handle NaN values\n",
    "    rsi_clean = rsi_series.dropna()\n",
    "    if rsi_clean.empty:\n",
    "        raise ValueError('RSI series contains only NaN values')\n",
    "    \n",
    "    try:\n",
    "        lower_threshold = rsi_clean.quantile(lower_quantile)\n",
    "        upper_threshold = rsi_clean.quantile(upper_quantile)\n",
    "        \n",
    "        # Ensure thresholds are within valid RSI range\n",
    "        lower_threshold = max(0, min(100, lower_threshold))\n",
    "        upper_threshold = max(0, min(100, upper_threshold))\n",
    "        \n",
    "        return lower_threshold, upper_threshold\n",
    "    except Exception as e:\n",
    "        logging.error(f'Error calculating RSI thresholds: {str(e)}')\n",
    "        raise\n",
    "\n",
    "def apply_rsi_labels(df, rsi_col='rsi', lower_threshold=30, upper_threshold=70):\n",
    "    \"\"\"Apply trading labels based on RSI values.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing RSI values\n",
    "        rsi_col (str): Name of the RSI column\n",
    "        lower_threshold (float): RSI oversold threshold\n",
    "        upper_threshold (float): RSI overbought threshold\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with new 'signal' column\n",
    "    \"\"\"\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise TypeError('df must be a pandas DataFrame')\n",
    "    \n",
    "    if rsi_col not in df.columns:\n",
    "        raise ValueError(f'Column {rsi_col} not found in DataFrame')\n",
    "    \n",
    "    # Create a copy to avoid modifying original\n",
    "    result = df.copy()\n",
    "    \n",
    "    try:\n",
    "        # Initialize signals column with 0 (hold)\n",
    "        result['signal'] = 0\n",
    "        \n",
    "        # Apply signals based on RSI thresholds\n",
    "        # Using boolean indexing to avoid ambiguity and ensure integer types\n",
    "        result.loc[result[rsi_col] <= lower_threshold, 'signal'] = 1  # Buy signal\n",
    "        result.loc[result[rsi_col] >= upper_threshold, 'signal'] = -1 # Sell signal\n",
    "        \n",
    "        # Ensure signal is integer type\n",
    "        result['signal'] = result['signal'].astype(int)\n",
    "        \n",
    "        # Verify signal values are discrete\n",
    "        unique_signals = set(result['signal'].unique())\n",
    "        expected_signals = {-1, 0, 1}\n",
    "        if not unique_signals.issubset(expected_signals):\n",
    "            raise ValueError(f'Invalid signal values found: {unique_signals}')\n",
    "        \n",
    "        return result\n",
    "    except Exception as e:\n",
    "        logging.error(f'Error applying RSI labels: {str(e)}')\n",
    "        raise\n",
    "\n",
    "# Calculate dynamic RSI thresholds\n",
    "try:\n",
    "    lower_thresh, upper_thresh = get_rsi_quantile_thresholds(df['rsi'])\n",
    "    print(f'✅ Dynamic RSI thresholds calculated:')\n",
    "    print(f'Lower (oversold) threshold: {lower_thresh:.2f}')\n",
    "    print(f'Upper (overbought) threshold: {upper_thresh:.2f}')\n",
    "    \n",
    "    # Apply trading signals\n",
    "    df = apply_rsi_labels(df, lower_threshold=lower_thresh, upper_threshold=upper_thresh)\n",
    "    \n",
    "    # Display signal distribution\n",
    "    signal_dist = df['signal'].value_counts()\n",
    "    print('\\nSignal distribution:')\n",
    "    display(signal_dist)\n",
    "    \n",
    "    # Basic signal statistics\n",
    "    print('\\nSignal transition matrix:')\n",
    "    display(pd.crosstab(df['signal'].shift(), df['signal']))\n",
    "except Exception as e:\n",
    "    print(f'❌ Error in feature engineering: {str(e)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda76aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def normalize_features(df):\n",
    "    \"\"\"\n",
    "    Normalize features while preserving binary columns and handling categorical data\n",
    "    \"\"\"\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise TypeError('Input must be a pandas DataFrame')\n",
    "        \n",
    "    try:\n",
    "        # Identify binary columns\n",
    "        binary_cols = ['ma_cross']  # Add any other binary columns here\n",
    "        binary_cols = [col for col in binary_cols if col in df.columns]\n",
    "        \n",
    "        # Store binary values\n",
    "        binary_data = df[binary_cols] if binary_cols else None\n",
    "        \n",
    "        # Get numeric columns excluding binary\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns.difference(binary_cols)\n",
    "        \n",
    "        # Normalize numeric features\n",
    "        scaler = StandardScaler()\n",
    "        df_normalized = pd.DataFrame(\n",
    "            scaler.fit_transform(df[numeric_cols]),\n",
    "            columns=numeric_cols,\n",
    "            index=df.index\n",
    "        )\n",
    "        \n",
    "        # Restore binary columns\n",
    "        if binary_data is not None:\n",
    "            df_normalized = pd.concat([df_normalized, binary_data], axis=1)\n",
    "            \n",
    "        # Verify feature ranges\n",
    "        for col in df_normalized.columns:\n",
    "            if col in binary_cols:\n",
    "                assert df_normalized[col].isin([0, 1]).all(), f\"Binary column {col} contains non-binary values\"\n",
    "            else:\n",
    "                assert -10 < df_normalized[col].mean() < 10, f\"Column {col} may not be properly normalized\"\n",
    "                \n",
    "        return df_normalized\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f'Error normalizing features: {str(e)}')\n",
    "        raise\n",
    "\n",
    "# Normalize features\n",
    "try:\n",
    "    df_normalized = normalize_features(df)\n",
    "    print('✅ Features normalized successfully')\n",
    "    print('\\nSummary statistics of normalized features:')\n",
    "    display(df_normalized.describe())\n",
    "except Exception as e:\n",
    "    print(f'❌ Error normalizing features: {str(e)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d0c709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze feature correlations\n",
    "try:\n",
    "    # Select only numeric columns for correlation analysis\n",
    "    numeric_cols = df_normalized.select_dtypes(include=['int64', 'float64']).columns\n",
    "    correlation_matrix = df_normalized[numeric_cols].corr()\n",
    "    \n",
    "    # Create correlation heatmap\n",
    "    fig = go.Figure(data=go.Heatmap(\n",
    "        z=correlation_matrix,\n",
    "        x=correlation_matrix.index,\n",
    "        y=correlation_matrix.index,\n",
    "        colorscale='RdBu',\n",
    "        zmin=-1,\n",
    "        zmax=1\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='Feature Correlation Matrix',\n",
    "        width=800,\n",
    "        height=800\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    # Find highly correlated features\n",
    "    threshold = 0.8\n",
    "    high_corr = np.where(np.abs(correlation_matrix) > threshold)\n",
    "    high_corr = [(correlation_matrix.index[x], correlation_matrix.columns[y], correlation_matrix.iloc[x, y]) \n",
    "                 for x, y in zip(*high_corr) if x != y]\n",
    "    \n",
    "    if high_corr:\n",
    "        print('\\nHighly correlated features (|correlation| > 0.8):')\n",
    "        for feat1, feat2, corr in high_corr:\n",
    "            print(f'{feat1} - {feat2}: {corr:.3f}')\n",
    "    else:\n",
    "        print('\\nNo highly correlated features found')\n",
    "        \n",
    "    # Print the correlation with the target variable (signal)\n",
    "    if 'signal' in df_normalized.columns:\n",
    "        print('\\nCorrelation with trading signal:')\n",
    "        signal_corr = df_normalized[numeric_cols].corrwith(df_normalized['signal']).sort_values(ascending=False)\n",
    "        display(signal_corr)\n",
    "except Exception as e:\n",
    "    print(f'❌ Error analyzing correlations: {str(e)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9792a6e",
   "metadata": {},
   "source": [
    "## Model Preparation and Training\n",
    "\n",
    "In this section, we'll:\n",
    "1. Prepare features and target variables\n",
    "2. Split the data into training and testing sets\n",
    "3. Handle class imbalance using SMOTE\n",
    "4. Train and optimize an XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae0201d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_model_data(df, feature_cols=None, target_col='signal', test_size=0.2, random_state=42):\n",
    "    \"\"\"Prepare data for model training with proper validation.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame\n",
    "        feature_cols (list): List of feature columns to use\n",
    "        target_col (str): Name of the target column\n",
    "        test_size (float): Proportion of data to use for testing\n",
    "        random_state (int): Random seed for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (X_train, X_test, y_train, y_test)\n",
    "    \"\"\"\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise TypeError('df must be a pandas DataFrame')\n",
    "    \n",
    "    if target_col not in df.columns:\n",
    "        raise ValueError(f'Target column {target_col} not found in DataFrame')\n",
    "    \n",
    "    # If feature columns not specified, use all except target\n",
    "    if feature_cols is None:\n",
    "        feature_cols = [col for col in df.columns if col != target_col]\n",
    "    \n",
    "    # Validate feature columns\n",
    "    missing_cols = [col for col in feature_cols if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f'Feature columns not found: {missing_cols}')\n",
    "    \n",
    "    try:\n",
    "        # Select features and target\n",
    "        X = df[feature_cols]\n",
    "        y = df[target_col]\n",
    "        \n",
    "        # Ensure target is integer type\n",
    "        y = y.astype(int)\n",
    "        \n",
    "        # Verify unique classes\n",
    "        unique_classes = set(y.unique())\n",
    "        expected_classes = {-1, 0, 1}\n",
    "        if not unique_classes.issubset(expected_classes):\n",
    "            raise ValueError(f'Invalid target values found: {unique_classes}. Expected: {expected_classes}')\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "        )\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "    except Exception as e:\n",
    "        logging.error(f'Error preparing model data: {str(e)}')\n",
    "        raise\n",
    "\n",
    "# Prepare model data\n",
    "try:\n",
    "    # Select features (excluding signal and any unwanted columns)\n",
    "    feature_cols = [\n",
    "        'rsi', 'bb_upper', 'bb_lower', 'bb_mid', 'bb_pct_b',\n",
    "        'sma_20', 'sma_50', 'ma_cross', 'price_momentum',\n",
    "        'atr', 'atr_pct'\n",
    "    ]\n",
    "    \n",
    "    # Verify features exist in normalized data\n",
    "    print('\\nChecking for features in normalized data...')\n",
    "    for col in feature_cols:\n",
    "        if col not in df_normalized.columns:\n",
    "            print(f'Missing feature: {col}')\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = prepare_model_data(\n",
    "        df_normalized, feature_cols=feature_cols\n",
    "    )\n",
    "    \n",
    "    print('✅ Data split successfully:')\n",
    "    print(f'Training set shape: {X_train.shape}')\n",
    "    print(f'Testing set shape: {X_test.shape}')\n",
    "    \n",
    "    # Handle class imbalance with SMOTE\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    print('\\nClass distribution before SMOTE:')\n",
    "    display(pd.Series(y_train).value_counts())\n",
    "    print('\\nClass distribution after SMOTE:')\n",
    "    display(pd.Series(y_train_balanced).value_counts())\n",
    "except Exception as e:\n",
    "    print(f'❌ Error preparing model data: {str(e)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fdb0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgboost_model(X_train, y_train, X_test, y_test, random_state=42):\n",
    "    \"\"\"Train and optimize XGBoost model with cross-validation.\n",
    "    \n",
    "    Args:\n",
    "        X_train (pd.DataFrame): Training features\n",
    "        y_train (pd.Series): Training targets\n",
    "        X_test (pd.DataFrame): Test features\n",
    "        y_test (pd.Series): Test targets\n",
    "        random_state (int): Random seed for reproducibility\n",
    "    \n",
    "           tuple: (trained_model)\n",
    "    \"\"\"\n",
    "    global reverse_mapper  # Make reverse_mapper accessible globally\n",
    "    try:\n",
    "        # Since our signals are already correctly labeled as [-1, 0, 1]\n",
    "        # and XGBoost needs labels starting from 0, we add 1 to shift the range\n",
    "        y_train_mapped = y_train + 1  # Converts [-1, 0, 1] to [0, 1, 2]\n",
    "        \n",
    "        # Create reverse mapper for predictions\n",
    "        reverse_mapper = {0: -1, 1: 0, 2: 1}\n",
    "        \n",
    "        # Define parameter grid for optimization\n",
    "        param_grid = {\n",
    "            'max_depth': [3, 4, 5],\n",
    "            'learning_rate': [0.01, 0.1],\n",
    "            'n_estimators': [100, 200],\n",
    "            'min_child_weight': [1, 3],\n",
    "            'gamma': [0, 0.1],\n",
    "            'subsample': [0.8, 0.9],\n",
    "            'colsample_bytree': [0.8, 0.9]\n",
    "        }\n",
    "        \n",
    "        # Initialize model with probability output\n",
    "        model = xgb.XGBClassifier(\n",
    "            objective='multi:softprob',  # Changed to output probabilities\n",
    "            num_class=3,  # [0, 1, 2]\n",
    "            random_state=random_state\n",
    "        )\n",
    "        \n",
    "        # Perform randomized search with cross-validation\n",
    "        random_search = RandomizedSearchCV(\n",
    "            model,\n",
    "            param_distributions=param_grid,\n",
    "            n_iter=10,\n",
    "            scoring='accuracy',\n",
    "            cv=StratifiedKFold(n_splits=5),\n",
    "            random_state=random_state,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        # Fit the model with mapped labels\n",
    "        random_search.fit(X_train, y_train_mapped)\n",
    "        \n",
    "        # Get best model and parameters\n",
    "        best_model = random_search.best_estimator_\n",
    "        best_params = random_search.best_params_\n",
    "        \n",
    "        # Get probability predictions\n",
    "        y_pred_proba = best_model.predict_proba(X_test)\n",
    "        # Convert to class predictions with confidence threshold\n",
    "        confidence_threshold = 0.4  # Adjust this threshold as needed\n",
    "        y_pred_mapped = np.argmax(y_pred_proba, axis=1)\n",
    "        max_probs = np.max(y_pred_proba, axis=1)\n",
    "        \n",
    "        # Only make non-hold predictions when confidence is high enough\n",
    "        # y_pred_mapped default is the max prob class. If confidence < threshold,\n",
    "        # we override it to 'hold' (which is mapped to 1).\n",
    "        y_pred_mapped[max_probs < confidence_threshold] = 1  \n",
    "        \n",
    "        # Convert predictions back to original labels\n",
    "        y_pred = pd.Series(y_pred_mapped).map(reverse_mapper)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        print(f'✅ Model training completed:')\n",
    "        print(f'Best parameters: {best_params}')\n",
    "        print(f'Test accuracy: {accuracy:.4f}')\n",
    "        \n",
    "        # Print classification report\n",
    "        print('\\nClassification Report:')\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        \n",
    "        return best_model, best_params\n",
    "    except Exception as e:\n",
    "        logging.error(f'Error training model: {str(e)}')\n",
    "        raise\n",
    "\n",
    "# The rest of your code block for feature importance plotting remains unchanged.\n",
    "# (No need to include it in this response unless you want to confirm specific changes there too)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424d7536",
   "metadata": {},
   "source": [
    "## Backtesting and Evaluation\n",
    "\n",
    "In this section, we'll:\n",
    "1. Implement a simple backtesting framework\n",
    "2. Calculate trading metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6114173b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest_strategy(df, predictions, initial_balance=10000, transaction_fee_pct=0.001,\n",
    "                      stop_loss_pct=None, take_profit_pct=None, position_sizing_pct=0.95):\n",
    "    \"\"\"Backtest the trading strategy with Stop-Loss, Take-Profit, and Position Sizing.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with price data (original, containing OHLCV).\n",
    "        predictions (pd.Series): Model predictions (-1: sell, 0: hold, 1: buy).\n",
    "        initial_balance (float): Initial trading balance.\n",
    "        transaction_fee_pct (float): Transaction fee as percentage.\n",
    "        stop_loss_pct (float, optional): Percentage below entry price to trigger stop-loss (e.g., 0.02 for 2%). Defaults to None.\n",
    "        take_profit_pct (float, optional): Percentage above entry price to trigger take-profit (e.g., 0.05 for 5%). Defaults to None.\n",
    "        position_sizing_pct (float): Percentage of current balance to allocate per trade (e.g., 0.95 for 95%).\n",
    "                                     Must be between 0.01 and 1.0. Defaults to 0.95.\n",
    "                                     \n",
    "    Returns:\n",
    "        tuple: (pd.DataFrame: DataFrame with individual trade records, pd.DataFrame: DataFrame with daily total portfolio value, dict: Summary metrics)\n",
    "    \"\"\"\n",
    "    if len(df) != len(predictions):\n",
    "        raise ValueError('Length of price data and predictions must match')\n",
    "    \n",
    "    results = df.copy() # Use a copy to add predictions\n",
    "    results['prediction'] = predictions.values # Ensure predictions are aligned\n",
    "    \n",
    "    # Initialize trading variables\n",
    "    balance = initial_balance\n",
    "    position = 0  # 0: no position, 1: long position\n",
    "    shares = 0\n",
    "    entry_price = 0 # Price at which the current position was opened\n",
    "    trades = [] # Stores individual buy/sell events\n",
    "    \n",
    "    # Track daily portfolio value for continuous plotting\n",
    "    daily_portfolio_values = [] \n",
    "\n",
    "    # Input validation for SL/TP/Position Sizing\n",
    "    if stop_loss_pct is not None and (not isinstance(stop_loss_pct, (int, float)) or stop_loss_pct <= 0):\n",
    "        raise ValueError(\"stop_loss_pct must be a positive number or None.\")\n",
    "    if take_profit_pct is not None and (not isinstance(take_profit_pct, (int, float)) or take_profit_pct <= 0):\n",
    "        raise ValueError(\"take_profit_pct must be a positive number or None.\")\n",
    "    if not isinstance(position_sizing_pct, (int, float)) or not (0.01 <= position_sizing_pct <= 1.0):\n",
    "        raise ValueError(\"position_sizing_pct must be a float between 0.01 and 1.0.\")\n",
    "\n",
    "    try:\n",
    "        for i in range(len(results)):\n",
    "            current_price = results.iloc[i]['close']\n",
    "            current_high = results.iloc[i]['high'] # Used for TP check\n",
    "            current_low = results.iloc[i]['low']   # Used for SL check\n",
    "            signal = results.iloc[i]['prediction']\n",
    "            current_date = results.index[i]\n",
    "            \n",
    "            # --- Handle existing position first (SL/TP or Model Exit) ---\n",
    "            exit_today = False\n",
    "            exit_reason = None\n",
    "            exit_price_actual = current_price # Default exit price is current_close\n",
    "\n",
    "            if position == 1: # We are currently in a long position\n",
    "                sl_triggered = False\n",
    "                tp_triggered = False\n",
    "                \n",
    "                # Calculate SL/TP levels based on entry price\n",
    "                sl_level = entry_price * (1 - stop_loss_pct) if stop_loss_pct is not None else None\n",
    "                tp_level = entry_price * (1 + take_profit_pct) if take_profit_pct is not None else None\n",
    "\n",
    "                # Check for Stop Loss trigger (prioritize SL if both hit on the same day)\n",
    "                if sl_level is not None and current_low <= sl_level:\n",
    "                    sl_triggered = True\n",
    "                    # Exit at SL price (or current_close if it went below SL and rebounded above it)\n",
    "                    exit_price_actual = sl_level # Assume execution at the stop-loss level\n",
    "                    exit_reason = 'stop_loss'\n",
    "                    exit_today = True\n",
    "                    logging.info(f\"SL HIT: {current_date} @ ${exit_price_actual:.2f} (Entry: ${entry_price:.2f})\")\n",
    "                \n",
    "                # Check for Take Profit trigger (only if SL NOT triggered)\n",
    "                if not sl_triggered and tp_level is not None and current_high >= tp_level:\n",
    "                    tp_triggered = True\n",
    "                    exit_price_actual = tp_level # Assume execution at the take-profit level\n",
    "                    exit_reason = 'take_profit'\n",
    "                    exit_today = True\n",
    "                    logging.info(f\"TP HIT: {current_date} @ ${exit_price_actual:.2f} (Entry: ${entry_price:.2f})\")\n",
    "\n",
    "                # If no SL/TP triggered, check model signal to exit\n",
    "                if not exit_today and (signal == -1 or signal == 0): # Model says sell or hold\n",
    "                    exit_today = True\n",
    "                    exit_reason = 'model_signal_exit'\n",
    "                    exit_price_actual = current_price # Exit at close price\n",
    "                    logging.info(f\"MODEL EXIT: {current_date} @ ${exit_price_actual:.2f} (Signal: {signal})\")\n",
    "            \n",
    "            if exit_today:\n",
    "                # Execute sell trade\n",
    "                value_of_shares_sold = shares * exit_price_actual\n",
    "                fee = value_of_shares_sold * transaction_fee_pct\n",
    "                balance += (value_of_shares_sold - fee)\n",
    "                \n",
    "                trades.append({\n",
    "                    'date': current_date,\n",
    "                    'type': 'sell',\n",
    "                    'price': exit_price_actual,\n",
    "                    'shares': shares,\n",
    "                    'fee': fee,\n",
    "                    'balance': balance,\n",
    "                    'total_value': balance, # After selling, total value is just cash\n",
    "                    'reason': exit_reason\n",
    "                })\n",
    "                shares = 0\n",
    "                position = 0 # No longer in a position\n",
    "                # After exiting, we do not re-enter on the same day in this daily bar model.\n",
    "\n",
    "            # --- Handle Buy Signal (only if not already exited today, and not in position) ---\n",
    "            # Using 'elif' ensures that if a position was exited (due to SL/TP/model), we don't try to re-enter on the same day.\n",
    "            elif position == 0 and signal == 1: # No position and model says buy\n",
    "                # Calculate the amount of cash to allocate for this trade, based on position_sizing_pct\n",
    "                cash_to_allocate = balance * position_sizing_pct\n",
    "\n",
    "                # Calculate the number of shares we can buy with this allocated cash, considering fees\n",
    "                # Shares = Cash_Allocated / (Price * (1 + Fee_Rate))\n",
    "                shares_to_buy = cash_to_allocate / (current_price * (1 + transaction_fee_pct))\n",
    "\n",
    "                # Calculate the total cost including fees for the allocated shares\n",
    "                total_trade_cost = shares_to_buy * current_price * (1 + transaction_fee_pct)\n",
    "\n",
    "                # Ensure we have enough balance for this trade and that we can buy at least a tiny amount\n",
    "                if balance >= total_trade_cost and shares_to_buy * current_price > 0.01: # Small threshold for meaningful trades (e.g., > $0.01)\n",
    "                    # Execute the buy\n",
    "                    balance -= total_trade_cost\n",
    "                    position = 1\n",
    "                    shares = shares_to_buy\n",
    "                    entry_price = current_price # Store entry price for SL/TP\n",
    "                    \n",
    "                    trades.append({\n",
    "                        'date': current_date,\n",
    "                        'type': 'buy',\n",
    "                        'price': current_price,\n",
    "                        'shares': shares,\n",
    "                        'fee': total_trade_cost - (shares * current_price), # Fee is total_cost - actual_asset_value\n",
    "                        'balance': balance,\n",
    "                        'total_value': balance + (shares * current_price), # Total value including new asset\n",
    "                        'reason': 'buy_signal'\n",
    "                    })\n",
    "                    logging.info(f\"BUY: {current_date} @ ${current_price:.2f}, Shares: {shares:.4f}, Balance: ${balance:.2f} (Allocated: {position_sizing_pct*100:.0f}%)\")\n",
    "                else:\n",
    "                    # Log why a buy might have failed (e.g., insufficient balance, too small an amount)\n",
    "                    if shares_to_buy * current_price <= 0.01:\n",
    "                        logging.debug(f\"Skipped BUY on {current_date}: Trade amount too small. Value: ${shares_to_buy * current_price:.2f}\")\n",
    "                    else:\n",
    "                        logging.warning(f\"Failed to BUY on {current_date}: Insufficient funds. Req: ${total_trade_cost:.2f}, Has: ${balance:.2f}\")\n",
    "\n",
    "\n",
    "            # --- Daily Portfolio Value Tracking (end of day snapshot) ---\n",
    "            current_portfolio_value = balance + (shares * current_price if position == 1 else 0)\n",
    "            daily_portfolio_values.append({\n",
    "                'date': current_date,\n",
    "                'total_value': current_portfolio_value\n",
    "            })\n",
    "\n",
    "        # Close any remaining position at the very end of the backtest period\n",
    "        if position == 1 and shares > 0:\n",
    "            final_price = results.iloc[-1]['close']\n",
    "            value_of_shares_sold = shares * final_price\n",
    "            fee = value_of_shares_sold * transaction_fee_pct\n",
    "            balance += (value_of_shares_sold - fee)\n",
    "            trades.append({\n",
    "                'date': results.index[-1],\n",
    "                'type': 'sell',\n",
    "                'price': final_price,\n",
    "                'shares': shares,\n",
    "                'fee': fee,\n",
    "                'balance': balance,\n",
    "                'total_value': balance,\n",
    "                'reason': 'end_of_backtest_close' # Clear reason\n",
    "            })\n",
    "            logging.info(f\"FINAL SELL: {results.index[-1]} @ ${final_price:.2f}, Shares: {shares:.4f}, Balance: ${balance:.2f}\")\n",
    "        \n",
    "        # Convert daily portfolio values to DataFrame\n",
    "        daily_portfolio_df = pd.DataFrame(daily_portfolio_values)\n",
    "        if not daily_portfolio_df.empty:\n",
    "            daily_portfolio_df.set_index('date', inplace=True)\n",
    "        else:\n",
    "            # Fallback: If no data or portfolio tracking failed, initialize with initial balance\n",
    "            daily_portfolio_df = pd.DataFrame([{'date': df.index[0], 'total_value': initial_balance}]).set_index('date')\n",
    "\n",
    "        # Convert individual trade records to DataFrame\n",
    "        trades_df = pd.DataFrame(trades)\n",
    "        if not trades_df.empty:\n",
    "            trades_df.set_index('date', inplace=True)\n",
    "            \n",
    "            # --- Calculate round-trip trade metrics ---\n",
    "            round_trip_trades = []\n",
    "            # We need to iterate through trades to match buys and sells\n",
    "            # This logic assumes sequential buy-sell pairs. If a buy is followed by another buy without an intervening sell,\n",
    "            # it implies being in a position and not exiting, which current logic doesn't support (only one position at a time).\n",
    "            # The current backtest only allows one open position at a time, so this pairing logic is suitable.\n",
    "            \n",
    "            buy_trade_info = None # Stores the buy trade record until a sell is found\n",
    "\n",
    "            for idx, row in trades_df.iterrows():\n",
    "                if row['type'] == 'buy':\n",
    "                    # If we encounter a buy before a previous one was closed, it's an error in logic or re-entering.\n",
    "                    # Given the current simple strategy, this implies the previous position was implicitly closed.\n",
    "                    # For more complex strategies, this might need more robust handling (e.g., closing previous position).\n",
    "                    if buy_trade_info is not None:\n",
    "                        logging.warning(f\"Unexpected BUY signal at {idx} while a BUY from {buy_trade_info.name} was still open. \"\n",
    "                                        \"This implies strategy re-entered without explicit sell. Closing previous trade for calculation.\")\n",
    "                        # Treat the previous open buy as implicitly closed at current price for metrics\n",
    "                        # (This is a workaround; ideally, the backtest logic ensures clear buy-sell pairs)\n",
    "                        round_trip_trades.append({\n",
    "                            'buy_date': buy_trade_info.name,\n",
    "                            'sell_date': idx, # Effectively \"sold\" at this date\n",
    "                            'buy_price': buy_trade_info['price'],\n",
    "                            'sell_price': row['price'], # Sold at the current price\n",
    "                            'shares': buy_trade_info['shares'],\n",
    "                            'return_pct': ((row['price'] * buy_trade_info['shares']) - buy_trade_info['fee'] - (row['price'] * buy_trade_info['shares'] * transaction_fee_pct)) / ((buy_trade_info['price'] * buy_trade_info['shares']) + buy_trade_info['fee']) -1 if (buy_trade_info['price'] * buy_trade_info['shares']) + buy_trade_info['fee'] != 0 else 0,\n",
    "                            'reason_exit': 'forced_re_entry_close'\n",
    "                        })\n",
    "                        buy_trade_info = None # Reset after forced close\n",
    "\n",
    "                    buy_trade_info = row.copy() # Store the entire buy record\n",
    "                    buy_trade_info['cost_basis'] = (buy_trade_info['price'] * buy_trade_info['shares']) + buy_trade_info['fee'] # Calculate initial cost basis\n",
    "\n",
    "                elif row['type'] == 'sell' and buy_trade_info is not None:\n",
    "                    sell_value_gross = row['price'] * row['shares']\n",
    "                    sell_value_net = sell_value_gross - row['fee']\n",
    "\n",
    "                    net_profit = sell_value_net - buy_trade_info['cost_basis']\n",
    "                    \n",
    "                    return_pct = net_profit / buy_trade_info['cost_basis'] if buy_trade_info['cost_basis'] != 0 else 0\n",
    "\n",
    "                    round_trip_trades.append({\n",
    "                        'buy_date': buy_trade_info.name, # Use index as date\n",
    "                        'sell_date': idx,\n",
    "                        'buy_price': buy_trade_info['price'],\n",
    "                        'sell_price': row['price'],\n",
    "                        'shares': row['shares'],\n",
    "                        'return_pct': return_pct,\n",
    "                        'reason_exit': row['reason'] # Reason for selling\n",
    "                    })\n",
    "                    buy_trade_info = None # Reset for next trade\n",
    "            \n",
    "            # Print performance metrics based on the *overall* portfolio value and round-trip trades\n",
    "            final_balance_overall = daily_portfolio_df.iloc[-1]['total_value'] if not daily_portfolio_df.empty else initial_balance\n",
    "            total_return_overall = (final_balance_overall - initial_balance) / initial_balance * 100\n",
    "            \n",
    "            print(f'\\n=== Trading Performance ===')\n",
    "            print(f'Initial Balance: ${initial_balance:.2f}')\n",
    "            print(f'Final Balance: ${final_balance_overall:.2f}')\n",
    "            print(f'Total Return: {total_return_overall:.2f}%')\n",
    "            \n",
    "            num_trades = len(round_trip_trades)\n",
    "            print(f'Number of Trades Executed: {num_trades}')\n",
    "\n",
    "            metrics_summary = { # Prepare metrics summary dict\n",
    "                'initial_balance': initial_balance,\n",
    "                'final_balance': final_balance_overall,\n",
    "                'total_return': total_return_overall,\n",
    "                'num_trades': num_trades,\n",
    "                'win_rate': 0.0, # Will be updated if trades exist\n",
    "                'avg_return_per_trade': 0.0,\n",
    "                'best_trade_return': 0.0,\n",
    "                'worst_trade_return': 0.0,\n",
    "            }\n",
    "\n",
    "            if num_trades > 0:\n",
    "                round_trip_df = pd.DataFrame(round_trip_trades)\n",
    "                profitable_trades = (round_trip_df['return_pct'] > 0).sum()\n",
    "                win_rate = (profitable_trades / num_trades) * 100\n",
    "                print(f'Win Rate (closed trades): {win_rate:.2f}%')\n",
    "                \n",
    "                print(f'Average Return per Trade: {round_trip_df[\"return_pct\"].mean()*100:.2f}%')\n",
    "                print(f'Best Trade Return: {round_trip_df[\"return_pct\"].max()*100:.2f}%')\n",
    "                print(f'Worst Trade Return: {round_trip_df[\"return_pct\"].min()*100:.2f}%')\n",
    "\n",
    "                # Update metrics_summary\n",
    "                metrics_summary['win_rate'] = win_rate\n",
    "                metrics_summary['avg_return_per_trade'] = round_trip_df[\"return_pct\"].mean()*100\n",
    "                metrics_summary['best_trade_return'] = round_trip_df[\"return_pct\"].max()*100\n",
    "                metrics_summary['worst_trade_return'] = round_trip_df[\"return_pct\"].min()*100\n",
    "            else:\n",
    "                print('No completed trades to calculate win rate or average returns.')\n",
    "\n",
    "        else: # trades_df is empty, meaning no buy trades were ever made\n",
    "            print('No trades were executed during the backtesting period.')\n",
    "            # Still provide overall balance\n",
    "            final_balance_overall = daily_portfolio_df.iloc[-1]['total_value'] if not daily_portfolio_df.empty else initial_balance\n",
    "            total_return_overall = (final_balance_overall - initial_balance) / initial_balance * 100\n",
    "            print(f'\\n=== Trading Performance (No Trades) ===')\n",
    "            print(f'Initial Balance: ${initial_balance:.2f}')\n",
    "            print(f'Final Balance: ${final_balance_overall:.2f}')\n",
    "            print(f'Total Return: {total_return_overall:.2f}%')\n",
    "            # metrics_summary defaults already handle this case\n",
    "\n",
    "        return trades_df, daily_portfolio_df, metrics_summary # <-- Now also returning the metrics summary\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f'Error in backtesting: {str(e)}')\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffec4e4",
   "metadata": {},
   "source": [
    "## Data Visualization\n",
    "\n",
    ". In the section we'll\n",
    "1. Visualize trading performance\n",
    "2. Visualize Volume\n",
    "3. Visualize daily porfolio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfb788e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_trading_results(df_with_indicators, trades_df, daily_portfolio_df, backtest_metrics=None):\n",
    "    \"\"\"Create interactive candlestick chart with trading signals, technical indicators, and performance metrics.\n",
    "    \n",
    "    Args:\n",
    "        df_with_indicators (pd.DataFrame): DataFrame with OHLCV and calculated technical indicators (RSI, BB, SMA, ATR).\n",
    "        trades_df (pd.DataFrame): DataFrame with trade information (buy/sell points).\n",
    "        daily_portfolio_df (pd.DataFrame): DataFrame with daily total portfolio value.\n",
    "        backtest_metrics (dict, optional): Dictionary containing pre-calculated metrics from backtest_strategy,\n",
    "                                         e.g., {'initial_balance', 'final_balance', 'total_return', 'num_trades', 'win_rate'}.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # --- DEBUGGING PRINTS ---\n",
    "        print(\"\\n--- Debugging Visualization Data ---\")\n",
    "        print(\"df_with_indicators columns:\", df_with_indicators.columns.tolist())\n",
    "        print(\"df_with_indicators head:\\n\", df_with_indicators.head())\n",
    "        \n",
    "        # Check for presence and NaNs in key indicator columns\n",
    "        indicator_cols_to_check = ['rsi', 'sma_20', 'sma_50', 'bb_upper', 'bb_mid', 'bb_lower', 'atr']\n",
    "        for col in indicator_cols_to_check:\n",
    "            if col not in df_with_indicators.columns:\n",
    "                print(f\"ERROR: Column '{col}' is NOT found in df_with_indicators for plotting!\")\n",
    "            else:\n",
    "                nan_count = df_with_indicators[col].isnull().sum()\n",
    "                if nan_count > 0:\n",
    "                    print(f\"WARNING: Column '{col}' has {nan_count} NaN values.\")\n",
    "                    # Drop NaNs from these specific columns for plotting robustness, might lose rows but ensures line draws\n",
    "                    df_with_indicators = df_with_indicators.dropna(subset=[col])\n",
    "                else:\n",
    "                    print(f\"Column '{col}' is present and has no NaNs.\")\n",
    "                print(f\"'{col}' stats: {df_with_indicators[col].describe()}\")\n",
    "        print(\"--- Show Visualization Data ---\\n\")\n",
    "\n",
    "        # Define subplot layout: 5 rows, 1 column\n",
    "        # Row 1: Price Action, Bollinger Bands & SMAs\n",
    "        # Row 2: Volume\n",
    "        # Row 3: ATR\n",
    "        # Row 4: RSI\n",
    "        # Row 5: Account Value\n",
    "        fig = make_subplots(rows=5, cols=1,\n",
    "                            shared_xaxes=True, # All X-axes will be linked\n",
    "                            vertical_spacing=0.02, # Slightly reduced spacing for compactness\n",
    "                            subplot_titles=('Price Action, Bollinger Bands & SMAs', 'Volume', 'ATR', 'RSI', 'Account Value'),\n",
    "                            row_heights=[0.45, 0.10, 0.15, 0.15, 0.15]) # Adjusted relative heights\n",
    "        \n",
    "        # --- Row 1, Column 1: Candlestick chart + Bollinger Bands + SMAs + Buy/Sell Signals ---\n",
    "        fig.add_trace(\n",
    "            go.Candlestick(x=df_with_indicators.index, \n",
    "                           open=df_with_indicators['open'],\n",
    "                           high=df_with_indicators['high'],\n",
    "                           low=df_with_indicators['low'],\n",
    "                           close=df_with_indicators['close'],\n",
    "                           name='OHLC'),\n",
    "            row=1, col=1\n",
    "        )\n",
    "        \n",
    "        # Bollinger Bands (overlayed on price chart)\n",
    "        if all(col in df_with_indicators.columns for col in ['bb_upper', 'bb_mid', 'bb_lower']):\n",
    "            fig.add_trace(go.Scatter(x=df_with_indicators.index, y=df_with_indicators['bb_upper'], \n",
    "                                     line=dict(color='orange', width=1), name='BB Upper', showlegend=True), \n",
    "                          row=1, col=1)\n",
    "            fig.add_trace(go.Scatter(x=df_with_indicators.index, y=df_with_indicators['bb_mid'], \n",
    "                                     line=dict(color='red', width=1, dash='dash'), name='BB Mid', showlegend=True), \n",
    "                          row=1, col=1)\n",
    "            fig.add_trace(go.Scatter(x=df_with_indicators.index, y=df_with_indicators['bb_lower'], \n",
    "                                     line=dict(color='green', width=1), name='BB Lower', showlegend=True), \n",
    "                          row=1, col=1)\n",
    "        else:\n",
    "            print(\"WARNING: Bollinger Bands columns missing, skipping plot.\")\n",
    "        \n",
    "        # Simple Moving Averages (overlayed on price chart)\n",
    "        if 'sma_20' in df_with_indicators.columns:\n",
    "            fig.add_trace(go.Scatter(x=df_with_indicators.index, y=df_with_indicators['sma_20'], \n",
    "                                     line=dict(color='blue', width=1.5), name='SMA 20', showlegend=True), \n",
    "                          row=1, col=1)\n",
    "        else:\n",
    "            print(\"WARNING: SMA 20 column missing, skipping plot.\")\n",
    "        if 'sma_50' in df_with_indicators.columns:\n",
    "            fig.add_trace(go.Scatter(x=df_with_indicators.index, y=df_with_indicators['sma_50'], \n",
    "                                     line=dict(color='white', width=1.5), name='SMA 50', showlegend=True), \n",
    "                          row=1, col=1)\n",
    "        else:\n",
    "            print(\"WARNING: SMA 50 column missing, skipping plot.\")\n",
    "\n",
    "        # Add buy markers\n",
    "        buys = trades_df[trades_df['type'] == 'buy']\n",
    "        if not buys.empty:\n",
    "            fig.add_trace(\n",
    "                go.Scatter(x=buys.index,\n",
    "                           y=buys['price'],\n",
    "                           mode='markers',\n",
    "                           name='Buy Signals',\n",
    "                           marker=dict(color='green', size=10, symbol='triangle-up'),\n",
    "                           text=[f'Buy @ ${p:.2f}' for p in buys['price']],\n",
    "                           hoverinfo='text'),\n",
    "                row=1, col=1\n",
    "            )\n",
    "        \n",
    "        # Add sell markers\n",
    "        sells = trades_df[trades_df['type'] == 'sell']\n",
    "        if not sells.empty:\n",
    "            fig.add_trace(\n",
    "                go.Scatter(x=sells.index,\n",
    "                           y=sells['price'],\n",
    "                           mode='markers',\n",
    "                           name='Sell Signals',\n",
    "                           marker=dict(color='red', size=10, symbol='triangle-down'),\n",
    "                           text=[f'Sell @ ${p:.2f}' for p in sells['price']],\n",
    "                           hoverinfo='text'),\n",
    "                row=1, col=1\n",
    "            )\n",
    "        \n",
    "        # --- Row 2, Column 1: Volume chart ---\n",
    "        fig.add_trace(\n",
    "            go.Bar(x=df_with_indicators.index, \n",
    "                   y=df_with_indicators['volume'],\n",
    "                   name='Volume',\n",
    "                   marker_color='darkblue',\n",
    "                   showlegend=True),\n",
    "            row=2, col=1\n",
    "        )\n",
    "        \n",
    "        # --- Row 3, Column 1: ATR chart ---\n",
    "        if 'atr' in df_with_indicators.columns:\n",
    "            fig.add_trace(go.Scatter(x=df_with_indicators.index, y=df_with_indicators['atr'], \n",
    "                                     name='ATR', line=dict(color='magenta')), \n",
    "                          row=3, col=1)\n",
    "        else:\n",
    "            print(\"WARNING: ATR column missing, skipping plot.\")\n",
    "\n",
    "        # --- Row 4, Column 1: RSI chart ---\n",
    "        if 'rsi' in df_with_indicators.columns:\n",
    "            fig.add_trace(go.Scatter(x=df_with_indicators.index, y=df_with_indicators['rsi'], \n",
    "                                     name='RSI', line=dict(color='cyan')), \n",
    "                          row=4, col=1)\n",
    "            # Add RSI overbought/oversold lines for context\n",
    "            fig.add_hline(y=70, line_dash=\"dash\", line_color=\"red\", row=4, col=1, annotation_text=\"Overbought\", annotation_position=\"top left\", annotation_font_color=\"red\")\n",
    "            fig.add_hline(y=30, line_dash=\"dash\", line_color=\"green\", row=4, col=1, annotation_text=\"Oversold\", annotation_position=\"bottom left\", annotation_font_color=\"green\")\n",
    "            fig.update_yaxes(range=[0, 100], row=4, col=1) # Fixed RSI range\n",
    "        else:\n",
    "            print(\"WARNING: RSI column missing, skipping plot.\")\n",
    "        \n",
    "        # --- Row 5, Column 1: Account Value ---\n",
    "        if not daily_portfolio_df.empty:\n",
    "            fig.add_trace(\n",
    "                go.Scatter(x=daily_portfolio_df.index,\n",
    "                           y=daily_portfolio_df['total_value'],\n",
    "                           name='Account Value',\n",
    "                           line=dict(color='purple')),\n",
    "                row=5, col=1\n",
    "            )\n",
    "        \n",
    "        # --- Update layout ---\n",
    "        fig.update_layout(\n",
    "            title_text='Trading Strategy Performance',\n",
    "            xaxis_rangeslider_visible=False, # Hide the default rangeslider that appears on the first subplot\n",
    "            hovermode='x unified', # Unify hover info across subplots by x-coordinate\n",
    "            height=1200, # Sufficient overall height for 5 rows\n",
    "            width=1200,\n",
    "            showlegend=True,\n",
    "            template='plotly_dark', # Set dark theme here!\n",
    "            \n",
    "            # Assign proper Y-axis titles for each row/subplot\n",
    "            yaxis=dict(title='Price'),  # Y-axis for Price (row=1)\n",
    "            yaxis2=dict(title='Volume'),# Y-axis for Volume (row=2)\n",
    "            yaxis3=dict(title='ATR'),   # Y-axis for ATR (row=3)\n",
    "            yaxis4=dict(title='RSI'),   # Y-axis for RSI (row=4)\n",
    "            yaxis5=dict(title='Value ($)'), # Y-axis for Account Value (row=5)\n",
    "\n",
    "            # Link X-axes (all are shared by default now) and ensure range slider is on the bottom one\n",
    "            xaxis5=dict(title='Date', rangeslider_visible=True) # Ensure range slider is visible on the very bottom axis\n",
    "        )\n",
    "        \n",
    "        # Add performance metrics as annotations\n",
    "        if backtest_metrics and not daily_portfolio_df.empty:\n",
    "            metrics_text = (\n",
    "                f\"Initial Balance: ${backtest_metrics['initial_balance']:,.2f}<br>\"\n",
    "                f\"Final Balance: ${backtest_metrics['final_balance']:,.2f}<br>\"\n",
    "                f\"Total Return: {backtest_metrics['total_return']:.2f}%<br>\"\n",
    "                f\"Number of Trades: {backtest_metrics['num_trades']}<br>\"\n",
    "                f\"Win Rate: {backtest_metrics['win_rate']:.2f}%\"\n",
    "            )\n",
    "            \n",
    "            fig.add_annotation(\n",
    "                xref='paper',\n",
    "                yref='paper',\n",
    "                x=1.0,\n",
    "                y=1.0, # Top right of the plot\n",
    "                text=metrics_text,\n",
    "                showarrow=False,\n",
    "                font=dict(size=12, color='white'), # Make text white for dark background\n",
    "                align='left',\n",
    "                bgcolor='rgba(0,0,0,0.6)', # Darker background for annotation\n",
    "                bordercolor='white', # White border for dark background\n",
    "                borderwidth=1,\n",
    "                borderpad=4\n",
    "            )\n",
    "        \n",
    "        fig.show()\n",
    "        return fig\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f'❌ Error in visualization: {str(e)}')\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbeb971",
   "metadata": {},
   "source": [
    " ## 🤖 Run Main Application!\n",
    "\n",
    " In the Section we'll\n",
    "\n",
    " Run the Pipeline to visualize the data for Crypto Algorithmic Trading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840d6786",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Execute the complete trading algorithm pipeline.\"\"\"\n",
    "    try:\n",
    "        # 1. Load and preprocess data\n",
    "        # Renamed to df_original for clarity; used for price & volume plotting later.\n",
    "        df_original = load_and_preprocess_data('test_df_features.csv') \n",
    "        # Create a working copy for feature engineering and transformations.\n",
    "        df_working = df_original.copy() \n",
    "        print(f'✅ Data loaded: {df_working.shape} records')\n",
    "        \n",
    "        # 2. Calculate technical indicators\n",
    "        df_working = calculate_technical_indicators(df_working)\n",
    "        print('✅ Technical indicators calculated')\n",
    "        \n",
    "        # Verify all technical indicators were created and present after NaN drops\n",
    "        # Ensure this list matches the new column names generated by calculate_technical_indicators\n",
    "        expected_features = [\n",
    "            'rsi', 'bb_upper', 'bb_lower', 'bb_mid', 'bb_pct_b',\n",
    "            'sma_20', 'sma_50', 'ma_cross', 'price_momentum',\n",
    "            'atr', 'atr_pct'\n",
    "        ]\n",
    "\n",
    "        # Filter expected_features to only include those that are actually in df_working AFTER calculation\n",
    "        # This makes the list more robust if some indicators aren't generated due to data issues or old TA libs\n",
    "        feature_cols_for_model = [col for col in expected_features if col in df_working.columns]\n",
    "\n",
    "        missing_features = [col for col in expected_features if col not in df_working.columns]\n",
    "        if missing_features:\n",
    "            # Change this to a warning if you don't want it to halt execution for missing optional features\n",
    "            logging.warning(f'Missing expected technical indicators after calculation: {missing_features}. Model will proceed with available features.')\n",
    "            \n",
    "        print('\\nAvailable features (after TI calc):', sorted(df_working.columns))\n",
    "        \n",
    "        # 3. Generate trading signals based on technical indicators\n",
    "        lower_thresh, upper_thresh = get_rsi_quantile_thresholds(df_working['rsi'])\n",
    "        df_working = apply_rsi_labels(df_working, lower_threshold=lower_thresh, upper_threshold=upper_thresh)\n",
    "        print('✅ Trading signals generated')\n",
    "        \n",
    "        # Store a copy of the df with TIs and signals *BEFORE* normalization for plotting\n",
    "        # This is the DataFrame with the correct new column names and values.\n",
    "        df_for_plotting = df_working.copy() \n",
    "\n",
    "        # 4. Normalize numerical features\n",
    "        df_normalized = normalize_features(df_working) # Pass df_working for normalization\n",
    "        print('✅ Features normalized')\n",
    "        \n",
    "        # Verify features after normalization (using the list of features actually passed to the model)\n",
    "        missing_normalized = [col for col in feature_cols_for_model if col not in df_normalized.columns]\n",
    "        if missing_normalized:\n",
    "            raise ValueError(f'Features missing after normalization for model training: {missing_normalized}')\n",
    "        \n",
    "        # 5. Prepare model data (split into train/test)\n",
    "        # Use the confirmed feature_cols_for_model list here\n",
    "        X_train, X_test, y_train, y_test = prepare_model_data(\n",
    "            df_normalized, feature_cols=feature_cols_for_model\n",
    "        )\n",
    "        \n",
    "        # 6. Handle class imbalance in training data using SMOTE\n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "        print('✅ Data prepared and balanced')\n",
    "        \n",
    "        # 7. Train and optimize the XGBoost model\n",
    "        model = train_xgboost_model(\n",
    "            X_train_balanced, y_train_balanced,\n",
    "            X_test, y_test\n",
    "        )\n",
    "        print('✅ Model trained')\n",
    "        \n",
    "        # 8. Generate predictions for backtesting on the full dataset\n",
    "        # Ensure X_full contains only the features actually used by the model\n",
    "        X_full = df_normalized[feature_cols_for_model] # Use the refined feature list\n",
    "        if X_full.empty:\n",
    "            raise ValueError(\"X_full is empty after feature selection/normalization, cannot generate predictions for backtesting.\")\n",
    "\n",
    "        pred_proba = model.predict_proba(X_full)\n",
    "        \n",
    "        # Apply a confidence threshold: if confidence in prediction is too low, default to 'hold' (0).\n",
    "        confidence_threshold = 0.35 \n",
    "        predictions_mapped = np.argmax(pred_proba, axis=1) \n",
    "        max_probs = np.max(pred_proba, axis=1) \n",
    "        \n",
    "        # If the highest probability is below the threshold, force the prediction to 'hold' (mapped value 1)\n",
    "        predictions_mapped[max_probs < confidence_threshold] = 1 \n",
    "        \n",
    "        # Map numerical predictions back to original trading signals [-1, 0, 1]\n",
    "        predictions = pd.Series(predictions_mapped).map(reverse_mapper)\n",
    "        \n",
    "        # Ensure predictions series has the same index as X_full for correct alignment with original data\n",
    "        predictions.index = X_full.index \n",
    "        \n",
    "        # Debugging: Print prediction distribution and confidence levels\n",
    "        print(\"\\nPrediction Distribution:\")\n",
    "        print(predictions.value_counts())\n",
    "        print(\"\\nConfidence Distribution:\")\n",
    "        print(f\"Mean confidence: {max_probs.mean():.3f}\")\n",
    "        print(f\"Min confidence: {max_probs.min():.3f}\")\n",
    "        print(f\"Max confidence: {max_probs.max():.3f}\")\n",
    "        print(f\"Predictions above threshold: {(max_probs >= confidence_threshold).sum()}\")\n",
    "        \n",
    "        print(\"\\nOriginal Signal Distribution:\")\n",
    "        print(df_working['signal'].value_counts()) \n",
    "\n",
    "        # 9. Run backtesting strategy\n",
    "        my_stop_loss_pct = 0.03 # 3% stop loss   \n",
    "        my_take_profit_pct = 0.10 \n",
    "        my_position_sizing_pct = 0.95 \n",
    "\n",
    "        # CORRECTED LINE: Pass df_for_plotting.loc[predictions.index]\n",
    "        trades_df, daily_portfolio_df, metrics_summary = backtest_strategy(\n",
    "            df_for_plotting.loc[predictions.index], # This DataFrame has the correct new TI column names\n",
    "            predictions,\n",
    "            stop_loss_pct=my_stop_loss_pct,\n",
    "            take_profit_pct=my_take_profit_pct,\n",
    "            position_sizing_pct=my_position_sizing_pct \n",
    "        )\n",
    "        \n",
    "        # 10. Visualize trading results\n",
    "        if not daily_portfolio_df.empty:\n",
    "            # CORRECTED LINE: Pass df_for_plotting.loc[predictions.index]\n",
    "            visualize_trading_results(\n",
    "                df_for_plotting.loc[predictions.index], # This DataFrame has the correct new TI column names\n",
    "                trades_df, \n",
    "                daily_portfolio_df, \n",
    "                backtest_metrics=metrics_summary \n",
    "            )\n",
    "        else:\n",
    "            print('⚠️ No daily portfolio data generated for visualization. This usually means no trades were executed or an error occurred in backtesting.')\n",
    "\n",
    "        return df_original, model, trades_df, daily_portfolio_df, metrics_summary \n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f'Error in main pipeline: {str(e)}')\n",
    "        raise\n",
    "\n",
    "# Execute the pipeline when the script is run\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        df_final, model_final, trades_df_final, daily_portfolio_df_final, metrics_summary_final = main()\n",
    "        print('✅ Trading pipeline completed successfully')\n",
    "    except Exception as e:\n",
    "        print(f'❌ Error executing trading pipeline: {str(e)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
